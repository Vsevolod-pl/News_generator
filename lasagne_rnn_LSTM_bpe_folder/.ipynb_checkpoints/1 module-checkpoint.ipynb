{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens =  1284\n",
      "Collecting https://github.com/lasagne/lasagne/archive/master.zip\n",
      "  Downloading https://github.com/lasagne/lasagne/archive/master.zip (227kB)\n",
      "\u001b[K    100% |################################| 235kB 2.1MB/s ta 0:00:011\n",
      "\u001b[?25h  Requirement already satisfied (use --upgrade to upgrade): Lasagne==0.2.dev1 from https://github.com/lasagne/lasagne/archive/master.zip in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages\n",
      "Requirement already satisfied: numpy in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from Lasagne==0.2.dev1)\n",
      "Collecting https://github.com/yandexdataschool/agentnet/archive/master.zip\n",
      "  Downloading https://github.com/yandexdataschool/agentnet/archive/master.zip (11.7MB)\n",
      "\u001b[K    100% |################################| 11.7MB 100kB/s eta 0:00:01\n",
      "\u001b[?25h  Requirement already satisfied (use --upgrade to upgrade): agentnet==0.10.6 from https://github.com/yandexdataschool/agentnet/archive/master.zip in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages\n",
      "Requirement already satisfied: six in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from agentnet==0.10.6)\n",
      "Requirement already satisfied: lasagne in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from agentnet==0.10.6)\n",
      "Requirement already satisfied: theano>=0.8.2 in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from agentnet==0.10.6)\n",
      "Requirement already satisfied: numpy>=1.9 in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from agentnet==0.10.6)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from theano>=0.8.2->agentnet==0.10.6)\n",
      "env: THEANO_FLAGS=floatX=float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/ipykernel/__main__.py:150: UserWarning: The parameter 'updates' of theano.function() expects an OrderedDict, got <class 'dict'>. Using a standard dictionary here results in non-deterministic behavior. You should use an OrderedDict if you are using Python 2.7 (theano.compat.OrderedDict for older python), or use a list of (shared, update) pairs. Do not just convert your dictionary to this type before the call as the conversion will still be non-deterministic.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import os\n",
    "start_token = \" \"\n",
    "\n",
    "with open(\"news.txt\",encoding='cp1251') as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token+name for name in names]\n",
    "    \n",
    "\"\"\"print ('n samples = ',len(names))\n",
    "for x in names[::1000]:\n",
    "    print (x)\n",
    "\"\"\"\n",
    "    \n",
    "from sklearn.cross_validation import train_test_split\n",
    "names_train, names_test = train_test_split(names, test_size=0.05, random_state=42)\n",
    "MAX_LENGTH = max(map(len,names))\n",
    "\n",
    "#import learn_bpe\n",
    "#learn_bpe.main(open(\"news.txt\",encoding='cp1251'), open(\"./bpes_sort.txt\",'w',encoding='cp1251'), 1000)\n",
    "from apply_bpe import BPE\n",
    "bpe = BPE( open(\"./bpes_sort.txt\",'r',encoding='cp1251'), '`')\n",
    "\n",
    "tokens=[' ']\n",
    "f=open(\"tokens.txt\",'r',encoding='cp1251')\n",
    "for i in f:\n",
    "    tokens.append(i.replace('\\n',\"\"))\n",
    "f.close()\n",
    "\n",
    "tokens = sorted(set(tokens))\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens = ',n_tokens)\n",
    "\n",
    "token_to_id = {token:ix for ix,token in enumerate(tokens)}\n",
    "\n",
    "def to_matrix(names,max_len=None,pad=token_to_id[' '],dtype='int32'):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    names = [[' '] + bpe.segment(names[i]).split() for i in range(len(names))]\n",
    "    max_len = max_len or max(map(len,names)) + 1\n",
    "    names_ix = np.zeros([len(names),max_len],dtype) + pad\n",
    "    \n",
    "    #print(max_len)\n",
    "    \n",
    "    for i in range(len(names)):\n",
    "        name_ix = [token_to_id.get(i, -1) for i in names[i]]\n",
    "        #print(names_ix[i,:len(name_ix)],name_ix)\n",
    "        #for j in range(len(name_ix)):\n",
    "            #names_ix[i,j] = name_ix[j]\n",
    "        #print(max_len-len(name_ix))\n",
    "        names_ix[i,:len(name_ix)] = name_ix\n",
    "       \n",
    "\n",
    "    return names_ix.T\n",
    "\n",
    "!pip3 install https://github.com/lasagne/lasagne/archive/master.zip\n",
    "!pip3 install https://github.com/yandexdataschool/agentnet/archive/master.zip\n",
    "    \n",
    "%env THEANO_FLAGS=floatX=float32\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import lasagne.layers as L\n",
    "\n",
    "n_tokens = len(tokens)\n",
    "rnn_num_units = 256\n",
    "embedding_size = 64\n",
    "\n",
    "from agentnet.memory import LSTMCell\n",
    "\n",
    "def log_softmax(a, axis=-1):\n",
    "    return a - T.log(T.exp(a).sum(axis=axis, keepdims=True))\n",
    "\n",
    "prev_token = L.InputLayer([None])\n",
    "prev_rnn = L.InputLayer([None, rnn_num_units])\n",
    "prev_rnn1 = L.InputLayer([None, rnn_num_units])\n",
    "\n",
    "# convert character id into embedding\n",
    "\n",
    "prev_token_emb = L.EmbeddingLayer(prev_token, n_tokens, embedding_size)\n",
    "\n",
    "# concatenate x embedding and previous h state\n",
    "#rnn_input = L.ConcatLayer([prev_token_emb, prev_rnn])\n",
    "\n",
    "# compute next state given x_and_h\n",
    "\n",
    "#new_rnn = L.DenseLayer(rnn_input, rnn_num_units, nonlinearity=T.tanh)\n",
    "\n",
    "\n",
    "(new_rnn,new_rnn1) = LSTMCell(prev_rnn,prev_rnn1,prev_token_emb) #GRUCell(prev_rnn1,[new_rnn])\n",
    "\n",
    "# get probabilities for language model P(x_next|h_next)\n",
    "next_token_logits = L.DenseLayer(new_rnn1, n_tokens, nonlinearity=None) #L.ConcatLayer([new_rnn,new_rnn1])\n",
    "\n",
    "next_token_probs = L.NonlinearityLayer(next_token_logits, T.nnet.softmax)\n",
    "next_token_logprobs = L.NonlinearityLayer(next_token_logits, log_softmax)\n",
    "\n",
    "input_sequence = T.imatrix(\"input tokens [time, batch]\")\n",
    "batch_size = input_sequence.shape[1]\n",
    "\n",
    "predicted_probas = []\n",
    "h0 = T.zeros([batch_size,rnn_num_units]) #initial hidden state\n",
    "h1 = T.zeros([batch_size,rnn_num_units])\n",
    "probas0 = T.zeros([batch_size, n_tokens])\n",
    "\n",
    "state0 = [h0,h1, probas0]\n",
    "\n",
    "def rnn_one_step(x_t, h_t, h1_t, prev_probas):\n",
    "    h_next, h1_next, next_logprobs = L.get_output([new_rnn,new_rnn1, next_token_logprobs],\n",
    "                           {\n",
    "                               #send x_t and h_t to the appropriate output\n",
    "                               prev_token: x_t,\n",
    "                               prev_rnn: h_t,\n",
    "                               prev_rnn1: h1_t\n",
    "                           })\n",
    "    \n",
    "    return h_next, h1_next, next_logprobs\n",
    "\n",
    "(h_seq, h1_seq, predicted_logprobas), upd = theano.scan(rnn_one_step, \n",
    "                                        outputs_info=state0, sequences=input_sequence)\n",
    "\n",
    "predictions_matrix = T.reshape(predicted_logprobas[:-1],[-1,len(tokens)])\n",
    "answers_flat = T.reshape(input_sequence[1:],[-1])\n",
    "\n",
    "loss = -(predictions_matrix * T.extra_ops.to_one_hot(answers_flat, n_tokens)).sum(axis=-1).mean()\n",
    "\n",
    "weights =  L.get_all_params([new_rnn,next_token_probs])\n",
    "all_grads = T.grad(loss, weights)\n",
    "scaled_grads = lasagne.updates.total_norm_constraint(all_grads, 100)\n",
    "optimizer = lasagne.updates.adam(scaled_grads, weights)\n",
    "\n",
    "\n",
    "train_step = theano.function([input_sequence], loss, updates=upd + optimizer)\n",
    "\n",
    "test_step=theano.function([input_sequence], loss)\n",
    "\n",
    "x_t = T.ivector('previous tokens')\n",
    "h_t = theano.shared(np.zeros([1,rnn_num_units],'float32'))\n",
    "h1_t = theano.shared(np.zeros([1,rnn_num_units],'float32'))\n",
    "\n",
    "h_next,h1_next,next_logprobs = rnn_one_step(x_t,h_t,h1_t,probas0)\n",
    "temp = theano.shared(np.float32(1))\n",
    "next_probs=T.nnet.softmax(next_logprobs/temp)\n",
    "\n",
    "update_rnn = theano.function([x_t], next_probs,\n",
    "                           updates={h_t : h_next,\n",
    "                                   h1_t:h1_next},\n",
    "                               allow_input_downcast=True)\n",
    "\n",
    "def test(samples):\n",
    "    return test_step(to_matrix(samples))\n",
    "\n",
    "def generate_sample(seed_phrase='',max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "        \n",
    "    parameters:\n",
    "        The phrase is set using the variable seed_phrase\n",
    "        The optional input \"N\" is used to set the number of characters of text to predict.     \n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in [' '] + bpe.segment(seed_phrase).split()]\n",
    "    \n",
    "    h_t.set_value(np.zeros([1,rnn_num_units],'float32'))\n",
    "    h1_t.set_value(np.zeros([1,rnn_num_units],'float32'))\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         _ = update_rnn([ix])\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs = update_rnn([x_sequence[-1]])\n",
    "        x_sequence.append(np.random.choice(n_tokens,p=x_probs[0]))\n",
    "        \n",
    "    return ' '.join([tokens[ix] for ix in x_sequence]).replace('` ', '')\n",
    "\n",
    "def save():\n",
    "    np.savez(\"weights_LSTM_bpe.npz\",*L.get_all_param_values([new_rnn,next_token_probs]))\n",
    "    \n",
    "def load():\n",
    "    with np.load('weights_LSTM_bpe.npz') as f:\n",
    "        param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    L.set_all_param_values([new_rnn,next_token_probs],param_values)\n",
    "    \n",
    "load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  футбол: «Локомотив» обыграл «Рубин» в матче молодежных команд                                                                                                                                                                                                                                                                                                                                                                              '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/ipykernel/__main__.py:18: DeprecationWarning: on_trait_change is deprecated in traitlets 4.1: use observe instead\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "result = widgets.Textarea()\n",
    "seed=widgets.Text()\n",
    "temp_slider=widgets.FloatSlider(min=0.001,max=2)\n",
    "btn = widgets.Button(description='Press me')\n",
    "\n",
    "def display_result(x):\n",
    "    if not seed.value.startswith(' '):\n",
    "        result.value=generate_sample(' '+seed.value)\n",
    "    else:\n",
    "        result.value=generate_sample(seed.value)\n",
    "def temp_change(x):\n",
    "    global temp\n",
    "    temp.set_value(temp_slider.value)\n",
    "\n",
    "temp_slider.on_trait_change(temp_change)\n",
    "btn.on_click(display_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(btn,seed,temp_slider,result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
