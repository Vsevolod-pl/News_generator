{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating names with recurrent neural networks (5 points)\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "start_token = \" \"\n",
    "\n",
    "with open(\"news.txt\",encoding='cp1251') as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token+name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n samples =  7413\n",
      " спорт: В Нефтеюганске чествовали юных акробатов\n",
      " Warhammer: Новое дополнение к Total War: Rome II вернёт игроков в античность\n",
      " политика: К ЧМ-2018 Ростводоканал внедрит систему глубокой очистки воздуха\n",
      " культура: Дмитров полностью подготовили к женскому чемпионату мира по хоккею\n",
      " наука: В Москве активно развивается предпрофессиональное образование\n",
      " Dota: Обзор LoL Catalyst. Помощник новичку в Лиге Легенд\n",
      " терроризм: Криминал гуляет у границ с Монголией и Китаем\n",
      " футбол: Новый понтонный мост установили на Мещерском озере\n"
     ]
    }
   ],
   "source": [
    "print ('n samples = ',len(names))\n",
    "for x in names[::1000]:\n",
    "    print (x)\n",
    "\n",
    "\n",
    "names_train=[]\n",
    "names_test=[]\n",
    "for x in names:\n",
    "    if(random.random()>0.5):\n",
    "        names_train.append(x)\n",
    "    else:\n",
    "        names_test.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length = 207\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH1qG62rnmAFdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f180e692208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len,names))\n",
    "print(\"max length =\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len,names)),bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need next to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import learn_bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn_bpe.main(open(\"news.txt\",encoding='cp1251'), open(\"./bpes_sort.txt\",'w',encoding='cp1251'), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from apply_bpe import BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bpe = BPE( open(\"./bpes_sort.txt\",'r',encoding='cp1251'), ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' '\n",
      "n_tokens =  1062\n"
     ]
    }
   ],
   "source": [
    "#all unique characters go here\n",
    "'''\n",
    "tokens = sorted(set(' '.join(names)))\n",
    "\n",
    "tokens = list(tokens)\n",
    "'''\n",
    "tokens=[' ']\n",
    "#bpe.segment(open(\"news.txt\",encoding='cp1251').readline())\n",
    "print(repr(tokens[0]))\n",
    "f=open(\"news.txt\",encoding='cp1251')\n",
    "\n",
    "for i in f:\n",
    "    tokens.extend(' '.join(bpe.segment(i).split(' ')).split())\n",
    "    #bpe.segment(i)\n",
    "\n",
    "tokens = sorted(set(tokens))\n",
    "tokens = list(tokens)\n",
    "\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens = ',n_tokens)\n",
    "\n",
    "#assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "theano string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {token:ix for ix,token in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems alright!\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "\n",
    "for i in range(n_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_matrix(names,max_len=None,pad=token_to_id[' '],dtype='int32'):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len,names))\n",
    "    names_ix = np.zeros([len(names),max_len],dtype) + pad\n",
    "    \n",
    "    #print(max_len)\n",
    "    \n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get,names[i]))\n",
    "        #print(names_ix[i,:len(name_ix)],name_ix)\n",
    "        #for j in range(len(name_ix)):\n",
    "            #names_ix[i,j] = name_ix[j]\n",
    "        #print(max_len-len(name_ix))\n",
    "        names_ix[i,:len(name_ix)] = name_ix\n",
    "       \n",
    "\n",
    "    return names_ix.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=480>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/lasagne/lasagne/archive/master.zip\n",
      "  Downloading https://github.com/lasagne/lasagne/archive/master.zip\n",
      "\u001b[K     | 235kB 3.6MB/ss\n",
      "  Requirement already satisfied (use --upgrade to upgrade): Lasagne==0.2.dev1 from https://github.com/lasagne/lasagne/archive/master.zip in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages\n",
      "Requirement already satisfied: numpy in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from Lasagne==0.2.dev1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install https://github.com/lasagne/lasagne/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/yandexdataschool/agentnet/archive/master.zip\n",
      "  Downloading https://github.com/yandexdataschool/agentnet/archive/master.zip\n",
      "\u001b[K     - 11.7MB 100.0MB/s\n",
      "  Requirement already satisfied (use --upgrade to upgrade): agentnet==0.10.6 from https://github.com/yandexdataschool/agentnet/archive/master.zip in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages\n",
      "Requirement already satisfied: six in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from agentnet==0.10.6)\n",
      "Requirement already satisfied: lasagne in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from agentnet==0.10.6)\n",
      "Requirement already satisfied: theano>=0.8.2 in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from agentnet==0.10.6)\n",
      "Requirement already satisfied: numpy>=1.9 in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from agentnet==0.10.6)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from theano>=0.8.2->agentnet==0.10.6)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install https://github.com/yandexdataschool/agentnet/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=floatX=float32\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=floatX=float32\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import lasagne.layers as L\n",
    "\n",
    "n_tokens = len(tokens)\n",
    "rnn_num_units = 256\n",
    "embedding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.memory import LSTMCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent neural network step that produces next state and output\n",
    "given prev input and previous state.\n",
    "We'll perform this step repeatedly to produce the whole sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_softmax(a, axis=-1):\n",
    "    return a - T.log(T.exp(a).sum(axis=axis, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_token = L.InputLayer([None])\n",
    "prev_rnn = L.InputLayer([None, rnn_num_units])\n",
    "prev_rnn1 = L.InputLayer([None, rnn_num_units])\n",
    "\n",
    "# convert character id into embedding\n",
    "\n",
    "prev_token_emb = L.EmbeddingLayer(prev_token, n_tokens, embedding_size)\n",
    "\n",
    "# concatenate x embedding and previous h state\n",
    "#rnn_input = L.ConcatLayer([prev_token_emb, prev_rnn])\n",
    "\n",
    "# compute next state given x_and_h\n",
    "\n",
    "#new_rnn = L.DenseLayer(rnn_input, rnn_num_units, nonlinearity=T.tanh)\n",
    "\n",
    "\n",
    "(new_rnn,new_rnn1) = LSTMCell(prev_rnn,prev_rnn1,prev_token_emb) #GRUCell(prev_rnn1,[new_rnn])\n",
    "\n",
    "# get probabilities for language model P(x_next|h_next)\n",
    "next_token_logits = L.DenseLayer(new_rnn1, n_tokens, nonlinearity=None) #L.ConcatLayer([new_rnn,new_rnn1])\n",
    "\n",
    "next_token_probs = L.NonlinearityLayer(next_token_logits, T.nnet.softmax)\n",
    "next_token_logprobs = L.NonlinearityLayer(next_token_logits, log_softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lasagne.layers.merge.ElemwiseMergeLayer at 0x7f1808fc7860>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN loop\n",
    "\n",
    "Once rnn_one_step is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.imatrix(\"input tokens [time, batch]\")\n",
    "batch_size = input_sequence.shape[1]\n",
    "\n",
    "predicted_probas = []\n",
    "h0 = T.zeros([batch_size,rnn_num_units]) #initial hidden state\n",
    "h1 = T.zeros([batch_size,rnn_num_units])\n",
    "probas0 = T.zeros([batch_size, n_tokens])\n",
    "\n",
    "state0 = [h0,h1, probas0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t, h1_t, prev_probas):\n",
    "    h_next, h1_next, next_logprobs = L.get_output([new_rnn,new_rnn1, next_token_logprobs],\n",
    "                           {\n",
    "                               #send x_t and h_t to the appropriate output\n",
    "                               prev_token: x_t,\n",
    "                               prev_rnn: h_t,\n",
    "                               prev_rnn1: h1_t\n",
    "                           })\n",
    "    \n",
    "    return h_next, h1_next, next_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(h_seq, h1_seq, predicted_logprobas), upd = theano.scan(rnn_one_step, \n",
    "                                        outputs_info=state0, sequences=input_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_matrix = T.reshape(predicted_logprobas[:-1],[-1,len(tokens)])\n",
    "answers_flat = T.reshape(input_sequence[1:],[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = -(predictions_matrix * T.extra_ops.to_one_hot(answers_flat, n_tokens)).sum(axis=-1).mean()\n",
    "\n",
    "weights =  L.get_all_params([new_rnn,next_token_probs])\n",
    "all_grads = T.grad(loss, weights)\n",
    "scaled_grads = lasagne.updates.total_norm_constraint(all_grads, 100)\n",
    "optimizer = lasagne.updates.adam(scaled_grads, weights)\n",
    "\n",
    "\n",
    "train_step = theano.function([input_sequence], loss, updates=upd + optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_step=theano.function([input_sequence], loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = T.ivector('previous tokens')\n",
    "h_t = theano.shared(np.zeros([1,rnn_num_units],'float32'))\n",
    "h1_t = theano.shared(np.zeros([1,rnn_num_units],'float32'))\n",
    "\n",
    "h_next,h1_next,next_logprobs = rnn_one_step(x_t,h_t,h1_t,probas0)\n",
    "temp = theano.shared(np.float32(1))\n",
    "next_probs=T.nnet.softmax(next_logprobs/temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/ipykernel/__main__.py:4: UserWarning: The parameter 'updates' of theano.function() expects an OrderedDict, got <class 'dict'>. Using a standard dictionary here results in non-deterministic behavior. You should use an OrderedDict if you are using Python 2.7 (theano.compat.OrderedDict for older python), or use a list of (shared, update) pairs. Do not just convert your dictionary to this type before the call as the conversion will still be non-deterministic.\n"
     ]
    }
   ],
   "source": [
    "update_rnn = theano.function([x_t], next_probs,\n",
    "                           updates={h_t : h_next,\n",
    "                                   h1_t:h1_next},\n",
    "                               allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(samples):\n",
    "    res=0\n",
    "    for x in samples:\n",
    "        batch = to_matrix(x,max_len=MAX_LENGTH)\n",
    "        res+=test_step(batch)\n",
    "    return res/len(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=' ',max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "        \n",
    "    parameters:\n",
    "        The phrase is set using the variable seed_phrase\n",
    "        The optional input \"N\" is used to set the number of characters of text to predict.     \n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    \n",
    "    h_t.set_value(np.zeros([1,rnn_num_units],'float32'))\n",
    "    h1_t.set_value(np.zeros([1,rnn_num_units],'float32'))\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         _ = update_rnn([ix])\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs = update_rnn([x_sequence[-1]])\n",
    "        x_sequence.append(np.random.choice(n_tokens,p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save():\n",
    "    np.savez(\"weights_LSTM.npz\",*L.get_all_param_values([new_rnn,next_token_probs]))\n",
    "    \n",
    "def load():\n",
    "    with np.load('weights_LSTM.npz') as f:\n",
    "        param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    L.set_all_param_values([new_rnn,next_token_probs],param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp.set_value(np.float32(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " наука: В площадке ГДА напоме покажителей отданичего дома с Россие                                                                                                                                             \n"
     ]
    }
   ],
   "source": [
    "print(generate_sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "history = []\n",
    "test_history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp.set_value(np.float32(1))\n",
    "history=[]\n",
    "test_history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-b07f9e519776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#batch = to_matrix(names_test[0],max_len=MAX_LENGTH)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mloss_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-9ed986c694af>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(samples)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    961\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    962\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    950\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/nbuser/.theano/compiledir_Linux-4.11--azure-x86_64-with-debian-stretch-sid-x86_64-3.5.4-64/scan_perform/mod.cpp:6946)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/theano/tensor/type.py\u001b[0m in \u001b[0;36mvalue_zeros\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \"\"\"\n\u001b[1;32m    554\u001b[0m         \u001b[0mCreate\u001b[0m \u001b[0man\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mof\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    batch = to_matrix(sample(names_train,32),max_len=MAX_LENGTH)\n",
    "    loss_i = train_step(batch)\n",
    "    #batch = to_matrix(names_test[0],max_len=MAX_LENGTH)\n",
    "    loss_test=test(names_test)\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    test_history.append(loss_test)\n",
    "    if (i+1)%100==0:\n",
    "        save()\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.plot(test_history,label='test')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        for _ in range(10):\n",
    "            print(generate_sample())\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: try it out!\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Theano\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* Ikea catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coming next\n",
    "\n",
    "* The easy way to train recurrent neural networks in Keras\n",
    "* Other problems solved with RNNs: sequence classification, sequential labelling\n",
    "* LSTM, GRU, OMGWTF\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "```\n",
    "\n",
    "```\n",
    "```\n",
    "\n",
    "```\n",
    "```\n",
    "\n",
    "```\n",
    "```\n",
    "\n",
    "```\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f=open('weights.wgt','wb')\n",
    "pickle.dump(weights,file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls -laht weights.wgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f=open('weights.wgt','rb')\n",
    "#pickle.dump(weights,file=f)\n",
    "weights=pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
